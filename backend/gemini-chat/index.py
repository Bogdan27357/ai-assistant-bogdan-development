import json
import os
from typing import Dict, Any
import requests
import psycopg2

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    '''
    Business: OpenRouter chat integration with single API key for all paid AI models
    Args: event with httpMethod, body (message, session_id, model_id)
    Returns: AI response from selected model via OpenRouter
    '''
    method: str = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type, X-User-Id',
                'Access-Control-Max-Age': '86400'
            },
            'body': '',
            'isBase64Encoded': False
        }
    
    if method != 'POST':
        return {
            'statusCode': 405,
            'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'Method not allowed'}),
            'isBase64Encoded': False
        }
    
    db_url = os.environ.get('DATABASE_URL')
    if not db_url:
        return {
            'statusCode': 500,
            'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'DATABASE_URL not configured'}),
            'isBase64Encoded': False
        }
    
    body_data = json.loads(event.get('body', '{}'))
    message = body_data.get('message', '')
    model_id = body_data.get('model_id', 'gemini')
    conversation_history = body_data.get('conversation_history', [])
    
    conn = psycopg2.connect(db_url)
    cur = conn.cursor()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ OpenRouter –∫–ª—é—á –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    cur.execute("SELECT api_key, enabled FROM api_keys WHERE model_id = 'openrouter' AND enabled = true")
    
    row = cur.fetchone()
    cur.close()
    conn.close()
    
    if not row or not row[0]:
        return {
            'statusCode': 400,
            'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'OpenRouter API key not configured. Please add it in admin panel'}),
            'isBase64Encoded': False
        }
    
    api_key = row[0]
    
    if not message:
        return {
            'statusCode': 400,
            'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'Message is required'}),
            'isBase64Encoded': False
        }
    
    conn = psycopg2.connect(db_url)
    cur = conn.cursor()
    cur.execute("SELECT file_name, content FROM knowledge_base ORDER BY created_at DESC LIMIT 10")
    knowledge_files = cur.fetchall()
    cur.close()
    conn.close()
    
    context = ""
    if knowledge_files:
        context = "\n\n=== –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π ===\n"
        for file_name, content in knowledge_files:
            context += f"\n[{file_name}]:\n{content[:1000]}\n"
        context += "===================\n\n"
    
    enhanced_message = f"{context}–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {message}"
    
    url = 'https://openrouter.ai/api/v1/chat/completions'
    
    # –£–º–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    message_lower = message.lower()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
    if any(word in message_lower for word in ['–∏–∑–æ–±—Ä–∞–∂–µ–Ω', '–∫–∞—Ä—Ç–∏–Ω–∫', '—Ñ–æ—Ç–æ', 'image', 'picture', 'photo', '—á—Ç–æ –Ω–∞', '–æ–ø–∏—à–∏', 'describe', 'vision']):
        # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - Gemini 2.0 Flash (–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è)
        auto_model = 'google/gemini-2.0-flash-exp:free'
        task_type = '–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'
    elif any(word in message_lower for word in ['–≥–µ–Ω–µ—Ä–∏—Ä', '–Ω–∞—Ä–∏—Å—É–π', '—Å–æ–∑–¥–∞–π –∫–∞—Ä—Ç–∏–Ω–∫', 'generate image', 'create image', 'draw']):
        # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - Flux
        auto_model = 'black-forest-labs/flux-1.1-pro'
        task_type = '–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'
    elif any(word in message_lower for word in ['–∫–æ–¥', 'code', '–ø—Ä–æ–≥—Ä–∞–º–º', 'function', 'debug', 'script', 'python', 'javascript', 'react', 'tsx', 'jsx']):
        # –î–ª—è –∫–æ–¥–∞ - DeepSeek (–ª—É—á—à–∏–π –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è)
        auto_model = 'deepseek/deepseek-chat:free'
        task_type = '–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ'
    elif any(word in message_lower for word in ['–ª–æ–≥–∏–∫–∞', 'reasoning', '—Ä–∞–∑–º—ã—à–ª', '–∞–Ω–∞–ª–∏–∑', '–ø–æ—á–µ–º—É', 'explain', '–¥–æ–∫–∞–∂–∏', 'proof']):
        # –î–ª—è –ª–æ–≥–∏–∫–∏ –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π - Llama –∏–ª–∏ Claude
        auto_model = 'anthropic/claude-3.5-sonnet:free'
        task_type = '–õ–æ–≥–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑'
    elif any(word in message_lower for word in ['—Ç–≤–æ—Ä—á', 'creative', '–∏—Å—Ç–æ—Ä', 'story', '—Å—Ç–∏—Ö', 'poem', '—Å–æ—á–∏–Ω', 'write']):
        # –î–ª—è —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞ - Claude
        auto_model = 'anthropic/claude-3.5-sonnet:free'
        task_type = '–¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ'
    elif any(word in message_lower for word in ['–º–∞—Ç–µ–º', 'math', 'calculate', '–≤—ã—á–∏—Å–ª', '—É—Ä–∞–≤–Ω–µ–Ω', 'equation', '—Ñ–æ—Ä–º—É–ª']):
        # –î–ª—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ - DeepSeek
        auto_model = 'deepseek/deepseek-chat:free'
        task_type = '–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞'
    elif any(word in message_lower for word in ['–ø–µ—Ä–µ–≤–æ–¥', 'translate', '–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π', 'to english', '–Ω–∞ —Ä—É—Å—Å–∫–∏–π', 'to russian']):
        # –î–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ - Qwen (–º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è)
        auto_model = 'qwen/qwen-2.5-72b-instruct:free'
        task_type = '–ü–µ—Ä–µ–≤–æ–¥'
    elif len(message) < 50:
        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –±—ã—Å—Ç—Ä—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ - Gemini (—Å–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è)
        auto_model = 'google/gemini-2.0-flash-thinking-exp:free'
        task_type = '–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç'
    else:
        # –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ - –±–∞–ª–∞–Ω—Å (Mistral –∏–ª–∏ Llama)
        auto_model = 'meta-llama/llama-3.3-70b-instruct:free'
        task_type = '–û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã'
    
    # –í—Å–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ OpenRouter (–æ–¥–∏–Ω API –∫–ª—é—á –¥–ª—è –≤—Å–µ—Ö)
    model_providers = {
        'gemini': {'provider': 'openrouter', 'model': 'google/gemini-2.0-flash-thinking-exp:free'},
        'gemini-vision': {'provider': 'openrouter', 'model': 'google/gemini-2.0-flash-exp:free'},
        'llama': {'provider': 'openrouter', 'model': 'meta-llama/llama-3.3-70b-instruct:free'},
        'llama-vision': {'provider': 'openrouter', 'model': 'meta-llama/llama-3.2-90b-vision-instruct:free'},
        'deepseek': {'provider': 'openrouter', 'model': 'deepseek/deepseek-chat:free'},
        'qwen': {'provider': 'openrouter', 'model': 'qwen/qwen-2.5-72b-instruct:free'},
        'qwen-vision': {'provider': 'openrouter', 'model': 'qwen/qwen-2-vl-72b-instruct:free'},
        'mistral': {'provider': 'openrouter', 'model': 'mistralai/mistral-large:free'},
        'claude': {'provider': 'openrouter', 'model': 'anthropic/claude-3.5-sonnet:free'},
        'flux': {'provider': 'openrouter', 'model': 'black-forest-labs/flux-1.1-pro'},
        'dalle': {'provider': 'openrouter', 'model': 'openai/dall-e-3'},
        'auto': {'provider': 'openrouter', 'model': auto_model}
    }
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    model_info = model_providers.get(model_id, model_providers['auto'])
    model_name = model_info['model']
    used_model_name = task_type if model_id == 'auto' else model_id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –Ω–µ—Ç
    is_image_gen = model_id in ['flux', 'dalle'] or (model_id == 'auto' and '–≥–µ–Ω–µ—Ä–∏—Ä' in message_lower)
    
    messages = []
    for msg in conversation_history:
        messages.append({'role': msg['role'], 'content': msg['content']})
    messages.append({'role': 'user', 'content': enhanced_message})
    
    # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ OpenRouter
    url = 'https://openrouter.ai/api/v1/chat/completions'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}',
        'HTTP-Referer': 'https://ai-platform.example.com',
        'X-Title': 'AI Platform'
    }
    
    if is_image_gen:
        payload = {'model': model_name, 'prompt': message, 'n': 1, 'size': '1024x1024'}
        stream_mode = False
    else:
        payload = {'model': model_name, 'messages': messages, 'stream': True}
        stream_mode = True
    
    response = requests.post(url, json=payload, headers=headers, stream=stream_mode)
    
    if response.status_code != 200:
        return {
            'statusCode': response.status_code,
            'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
            'body': json.dumps({'error': f'OpenRouter API error: {response.text}'}),
            'isBase64Encoded': False
        }
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenRouter
    ai_response = ''
    
    if is_image_gen:
        data = response.json()
        image_url = data.get('data', [{}])[0].get('url', '')
        if image_url:
            ai_response = f'üé® –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!\n\n![Generated Image]({image_url})\n\nURL: {image_url}'
        else:
            ai_response = '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'
    else:
        # OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        for line in response.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                if line_str.startswith('data: '):
                    data_str = line_str[6:]
                    if data_str.strip() == '[DONE]':
                        break
                    try:
                        chunk = json.loads(data_str)
                        content = chunk.get('choices', [{}])[0].get('delta', {}).get('content', '')
                        ai_response += content
                    except:
                        continue
    
    return {
        'statusCode': 200,
        'headers': {'Access-Control-Allow-Origin': '*', 'Content-Type': 'application/json'},
        'body': json.dumps({
            'response': ai_response,
            'model': model_name,
            'provider': 'OpenRouter',
            'task_type': used_model_name,
            'is_image': is_image_gen
        }),
        'isBase64Encoded': False
    }